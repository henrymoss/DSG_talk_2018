{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import os, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "%pylab inline\n",
    "\n",
    "#ML libraries\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizerSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "#BO libraries\n",
    "import GPy\n",
    "import GPyOpt\n",
    "rs=1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preparation and loading\n",
    "np.random.seed(rs)\n",
    "random.seed(rs)\n",
    "text=[]\n",
    "clas = []\n",
    "classname = [\"pos\", \"neg\"]\n",
    "#load training examples\n",
    "for item in classname:\n",
    "    for file in os.listdir(\"Data/aclImdb/test/\" +item ):\n",
    "            filename = \"Data/aclImdb/test/\" +item + \"//\"+file\n",
    "            fl = open(filename, \"r\", encoding=\"utf8\").read()\n",
    "            fl = re.sub(\"\\n\", \" \", fl)\n",
    "            text.append(fl)\n",
    "            clas.append(item)\n",
    "#load testing examples\n",
    "for item in classname:\n",
    "    for file in os.listdir(\"Data/aclImdb/train/\" +item ):\n",
    "            filename = \"Data/aclImdb/train/\" +item + \"//\"+file\n",
    "            fl = open(filename, \"r\", encoding=\"utf8\").read()\n",
    "            fl = re.sub(\"\\n\", \" \", fl)\n",
    "            text.append(fl)\n",
    "            clas.append(item)\n",
    "#store in dataframe\n",
    "dataframe = pd.DataFrame(clas, columns=['class'])\n",
    "dataframe[\"text\"] = text\n",
    "dataframe = shuffle(dataframe)\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "print(\"We have \"+str(len(text))+\" classified examples\")\n",
    "\n",
    "#choose 5000 to be fixed training set\n",
    "#leave remaing 45000 to be test set/represent the population\n",
    "Y = dataframe[\"class\"].tolist()\n",
    "X = dataframe[\"text\"].tolist()\n",
    "X_train_fixed=X[:1000]\n",
    "Y_train_fixed=Y[:1000]\n",
    "X_pop=X[1000:]\n",
    "Y_pop=Y[1000:]\n",
    "#prepare for training\n",
    "count_vect = CountVectorizer(min_df = 10, ngram_range = (1, 3),stop_words=\"english\",analyzer='word',max_features=500)\n",
    "X_train_counts = count_vect.fit_transform(X_train_fixed)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_fixed_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_pop_counts=count_vect.transform(X_pop)\n",
    "X_pop_tfidf=tfidf_transformer.transform(X_pop_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up domain of parameters\n",
    "#specify if continous and give a range\n",
    "# or if discrete give a list of possible values\n",
    "domain=[{'name': 'max_features',      'type': 'continuous', 'domain': (0.00001,1)},\n",
    "    {'name': 'max_depth', 'type':'discrete', 'domain':tuple(range(2,6))},\n",
    "    {'name': 'min_samples_split',  'type': 'continuous', 'domain': (0.00000001,0.5)},\n",
    "    {'name': 'min_samples_leaf',  'type': 'continuous', 'domain': (0.00000001,0.5)}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the function to optimize: The performance of our ML model\n",
    "def fit_RF(x):\n",
    "    x = np.atleast_2d(x)\n",
    "    fs = np.zeros((x.shape[0],1))\n",
    "    for i in range(x.shape[0]):\n",
    "        clf=RandomForestClassifier(random_state=1234,n_estimators=1000,max_features=x[i,0],max_depth=int(x[i,1]),min_samples_split=x[i,2],min_samples_leaf=x[i,3],n_jobs=4)\n",
    "        fs[i]=-np.mean(cross_validate(clf, X_train_fixed_tfidf, Y_train_fixed, cv=5,n_jobs=5)['test_score'])\n",
    "    return fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat many times\n",
    "many_scores2=[]\n",
    "for j in range(0,50):\n",
    "    print(j)\n",
    "    #set up and initialize BO model\n",
    "    opt = GPyOpt.methods.BayesianOptimization(f =fit_RF,  # function to optimize       \n",
    "                                          domain = domain,         # box-constrains of the problem\n",
    "                                          acquisition_type ='LCB',\n",
    "                                          initial_design_type=\"random\",\n",
    "                                          initial_design_numdata=15,\n",
    "                                          kernel=GPy.kern.Matern52(len(domain)) #type of Gaussian Process most appropriate for ML models\n",
    "                                         )   \n",
    "    opt.run_optimization(max_iter=66)  \n",
    "    scores=opt.Y*[-1]\n",
    "    scores=[np.max(scores[:i]) for i in range(1,len(scores))]\n",
    "    many_scores2.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
